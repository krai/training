./convert.sh: line 33: [: : integer expression expected
STARTING TIMING RUN AT 2022-06-17 10:11:55 AM
running benchmark
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
:::MLLOG {"namespace": "", "time_ms": 1655460721427, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "convert.py", "lineno": 121}}
:::MLLOG {"namespace": "", "time_ms": 1655460721479, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "convert.py", "lineno": 122}}
:::MLLOG {"namespace": "", "time_ms": 1655460721479, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "convert.py", "lineno": 123}}
:::MLLOG {"namespace": "", "time_ms": 1655460721479, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "convert.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1655460721500, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3235719397, "metadata": {"file": "convert.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1655460721500, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 16, "metadata": {"file": "convert.py", "lineno": 140}}
:::MLLOG {"namespace": "", "time_ms": 1655460721500, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 32, "metadata": {"file": "convert.py", "lineno": 141}}
:::MLLOG {"namespace": "", "time_ms": 1655460721501, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 30, "metadata": {"file": "convert.py", "lineno": 142}}
:::MLLOG {"namespace": "", "time_ms": 1655460721501, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "convert.py", "lineno": 143}}
Namespace(amp=True, backbone='resnext50_32x4d', batch_size=16, data_augmentation='hflip', data_layout='channels_last', data_path='/datasets/coco2017', dataset='coco', device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, epochs=30, eval_batch_size=16, eval_print_freq=20, gpu=0, image_size=[800, 800], lr=0.0001, output_dir='/results', pretrained=False, print_freq=20, rank=0, resume='/model/openimage_train_coco_finetune_model_12_acc35.pth', resume_from_diff_dataset=False, seed=3235719397, start_epoch=0, sync_bn=False, target_map=0.37, test_only=False, trainable_backbone_layers=3, warmup_epochs=2, warmup_factor=0.001, workers=4, world_size=2)
Getting dataset information
Number of classes  91
Creating model
:::MLLOG {"namespace": "", "time_ms": 1655460721508, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 195, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721511, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 197, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721511, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 195, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721514, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 197, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721500, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3235719398, "metadata": {"file": "convert.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1655460721663, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721663, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721663, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721664, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721664, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721664, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721665, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721665, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721665, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721666, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721666, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721666, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721667, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721667, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721668, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721669, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721670, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721670, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721672, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721672, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721673, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721674, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721675, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721675, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721676, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721678, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721678, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721681, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721684, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721687, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721688, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721690, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721693, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721694, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721697, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721700, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721701, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721704, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721707, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721707, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721710, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721713, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721713, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721716, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721756, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721758, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721768, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721779, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721781, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/resnet.py", "lineno": 187, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721872, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 94, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721873, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 96, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721874, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 94, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721875, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 96, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721876, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 94, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721878, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 96, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721878, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 94, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721881, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 96, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721882, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 94, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721885, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 96, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721885, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 94, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721888, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/feature_pyramid_network.py", "lineno": 96, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721900, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 90, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721904, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 92, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721904, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 90, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721907, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 92, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721907, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 90, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721910, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 92, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721910, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 90, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721914, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 92, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721923, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 96, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721932, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 98, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721944, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 180, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721945, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 182, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721945, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 187, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721948, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 189, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721948, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 187, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721951, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 189, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721951, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 187, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721955, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 189, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721955, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 187, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721958, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "model/retinanet.py", "lineno": 189, "tensor": "module.head.regression_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1655460721997, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "convert.py", "lineno": 175}}
:::MLLOG {"namespace": "", "time_ms": 1655460721997, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0001, "metadata": {"file": "convert.py", "lineno": 176}}
:::MLLOG {"namespace": "", "time_ms": 1655460721997, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "convert.py", "lineno": 177}}
:::MLLOG {"namespace": "", "time_ms": 1655460721997, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 2, "metadata": {"file": "convert.py", "lineno": 178}}
:::MLLOG {"namespace": "", "time_ms": 1655460721997, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "convert.py", "lineno": 179}}
:::MLLOG {"namespace": "", "time_ms": 1655460721997, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "convert.py", "lineno": 180}}
Converting ...
/opt/conda/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/opt/conda/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Debug Out: /workspace/ssd/model/retinanet.py:507: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  for img in images:
/workspace/ssd/model/transform.py:70: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  images = [img for img in images]
/workspace/ssd/model/transform.py:113: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  mean = torch.as_tensor(self.image_mean, dtype=dtype, device=device)
/workspace/ssd/model/transform.py:114: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  std = torch.as_tensor(self.image_std, dtype=dtype, device=device)
[{'boxes': tensor([[  0.0000,   0.0000, 800.0000, 796.0743],
        [  2.6773,   2.0358, 800.0000, 793.4287],
        [  0.0000,   0.0000, 800.0000, 797.9634],
        [  3.7437,   2.9175, 795.5377, 791.4492],
        [ 10.5312, 459.0361, 795.9473, 796.2778],
        [  0.0000,   1.9123, 800.0000, 799.6531],
        [125.1168,   4.4013, 796.2618, 374.2094],
        [  0.0000,  15.4129, 626.7622, 519.0577],
        [  0.0000,  15.4129, 626.7622, 519.0577],
        [  2.7088,   6.3957, 800.0000, 783.7470],
        [  0.0000, 410.8930, 800.0000, 797.9227],
        [112.2437,   6.8171, 800.0000, 369.3879],
        [  2.2823,   5.9578, 800.0000, 795.0369]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3802, 0.1639, 0.1559, 0.1016, 0.0706, 0.0682, 0.0680, 0.0628, 0.0592,
        0.0587, 0.0576, 0.0534, 0.0534], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82, 44,  1, 67,  3, 84, 44, 44,  1, 64,  1,  1, 78], device='cuda:0')}, {'boxes': tensor([[  1.3167,   8.8809, 800.0000, 793.0142],
        [  3.4895,   8.3912, 800.0000, 793.4358],
        [  3.4120,   0.9430, 800.0000, 793.2246],
        [  3.0503,   1.9163, 794.8064, 793.6518],
        [  1.3167,   8.8809, 800.0000, 793.0142],
        [123.9438,  12.2808, 800.0000, 366.5694],
        [  0.8010,   6.0183, 797.5035, 788.3475],
        [  7.9003, 445.7895, 776.2778, 790.2728],
        [108.5397,   1.9675, 800.0000, 303.8520],
        [ 40.9954, 435.3737, 783.9965, 787.9366],
        [  1.3167,   8.8809, 800.0000, 793.0142],
        [208.2674, 348.0815, 788.5847, 789.7136],
        [  0.0000,   0.8283, 790.2651, 345.2514]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3630, 0.1673, 0.1391, 0.0905, 0.0716, 0.0675, 0.0613, 0.0595, 0.0589,
        0.0586, 0.0572, 0.0559, 0.0533], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 84, 44, 64,  3,  1,  1, 78, 82, 67], device='cuda:0')}, {'boxes': tensor([[2.3511e-01, 7.9426e+00, 8.0000e+02, 7.9341e+02],
        [2.2858e-02, 5.9268e-01, 8.0000e+02, 7.9659e+02],
        [4.3068e+00, 1.8665e+00, 8.0000e+02, 7.9374e+02],
        [3.5055e+00, 4.8407e+00, 7.9882e+02, 7.9376e+02],
        [2.0471e+00, 1.6370e+01, 5.8021e+02, 5.2916e+02],
        [1.5562e+00, 7.0102e+00, 8.0000e+02, 7.8766e+02],
        [6.8039e-01, 2.0280e+00, 8.0000e+02, 7.9881e+02],
        [2.0471e+00, 1.6370e+01, 5.8021e+02, 5.2916e+02],
        [1.4770e+02, 7.5222e+00, 8.0000e+02, 3.6435e+02],
        [2.4701e+01, 4.1821e+02, 7.9068e+02, 7.9620e+02],
        [5.0530e+00, 4.4344e+02, 7.8165e+02, 7.9702e+02],
        [9.6685e+01, 0.0000e+00, 7.9779e+02, 2.9102e+02],
        [2.3511e-01, 7.9426e+00, 8.0000e+02, 7.9341e+02],
        [4.5556e+02, 5.9894e+01, 8.0000e+02, 7.4379e+02],
        [4.3908e+02, 9.4656e+00, 8.0000e+02, 6.9171e+02]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3546, 0.1929, 0.1636, 0.0957, 0.0687, 0.0657, 0.0654, 0.0648, 0.0623,
        0.0589, 0.0589, 0.0536, 0.0530, 0.0519, 0.0511], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67,  1, 64, 84, 44, 44,  1,  3,  1, 78, 82, 44],
       device='cuda:0')}, {'boxes': tensor([[  2.3293,   0.0000, 800.0000, 796.4565],
        [  0.0000,   1.3654, 800.0000, 798.1257],
        [  4.0116,   2.5018, 800.0000, 793.4446],
        [  3.4431,   4.2812, 797.2164, 792.9032],
        [184.6581,   9.1602, 800.0000, 371.9777],
        [  0.0000,   0.0000, 623.2924, 301.0413],
        [  1.7362,  10.4462, 800.0000, 794.1760],
        [  2.2901,   8.1842, 799.2873, 786.1616],
        [  0.0000,  14.8125, 596.4276, 527.5032],
        [454.9170,  19.9302, 800.0000, 688.9124],
        [463.8337,  72.1205, 800.0000, 739.7194],
        [ 21.7077, 472.3113, 767.5944, 796.4893],
        [  1.7362,  10.4462, 800.0000, 794.1760],
        [152.1302,   0.9700, 800.0000, 310.3235],
        [ 83.6446, 412.1683, 800.0000, 792.7603]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3713, 0.1785, 0.1405, 0.0840, 0.0747, 0.0687, 0.0628, 0.0606, 0.0596,
        0.0572, 0.0562, 0.0531, 0.0520, 0.0513, 0.0500], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 44, 44, 84, 64,  1, 44, 82,  3, 78,  1,  1],
       device='cuda:0')}, {'boxes': tensor([[1.3685e+00, 0.0000e+00, 8.0000e+02, 7.9623e+02],
        [1.1361e+00, 3.9742e+00, 8.0000e+02, 7.9816e+02],
        [3.8405e+00, 2.1881e+00, 8.0000e+02, 7.9313e+02],
        [3.4413e+00, 2.9047e+00, 7.9745e+02, 7.9243e+02],
        [2.4565e+00, 7.6530e+00, 8.0000e+02, 7.8662e+02],
        [6.1523e-02, 1.6225e+01, 6.0780e+02, 5.2384e+02],
        [9.4910e-01, 1.0399e+01, 8.0000e+02, 7.9367e+02],
        [2.0711e+02, 9.1510e+00, 7.9776e+02, 3.8146e+02],
        [5.9485e+01, 0.0000e+00, 7.5266e+02, 2.9157e+02],
        [2.6664e+01, 4.4020e+02, 7.7752e+02, 7.9132e+02],
        [5.9037e+00, 5.6918e+00, 7.9784e+02, 7.9120e+02],
        [8.7776e+01, 3.8746e+02, 8.0000e+02, 7.9268e+02],
        [2.0624e+02, 5.0861e+01, 3.8328e+02, 4.0428e+02],
        [0.0000e+00, 2.9102e+00, 7.7833e+02, 3.3111e+02]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3161, 0.1916, 0.1494, 0.0861, 0.0711, 0.0699, 0.0657, 0.0610, 0.0590,
        0.0578, 0.0566, 0.0535, 0.0517, 0.0503], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 64,  1, 84, 44,  1,  3, 59,  1, 44, 67],
       device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 800.0000, 795.3143],
        [  2.0761,   3.2036, 800.0000, 796.1017],
        [  4.5426,   1.5023, 800.0000, 794.3941],
        [  3.5031,   1.9320, 797.3630, 793.1038],
        [  8.5653, 443.6886, 792.7122, 793.5167],
        [143.6936,   7.5053, 795.8776, 385.5674],
        [  9.3940, 413.5120, 800.0000, 789.8716],
        [  0.0000,  11.3088, 800.0000, 793.2371],
        [  1.0091,   6.7999, 800.0000, 786.2588],
        [  0.0000,  13.0179, 624.5521, 517.7733],
        [146.2293, 395.0819, 794.8682, 789.8141],
        [451.3235,  13.7803, 800.0000, 687.7736]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3694, 0.1560, 0.1553, 0.0918, 0.0702, 0.0686, 0.0676, 0.0671, 0.0659,
        0.0621, 0.0515, 0.0505], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67,  3, 44,  1, 84, 64,  1, 44, 44], device='cuda:0')}, {'boxes': tensor([[  1.2946,   9.7367, 800.0000, 792.9683],
        [  3.6082,   7.7835, 800.0000, 794.1192],
        [  6.7876,   1.5279, 800.0000, 794.7452],
        [  3.9817,   3.2357, 796.2123, 792.7869],
        [  1.2946,   9.7367, 800.0000, 792.9683],
        [189.2710,   7.2621, 792.7920, 374.3013],
        [  1.7240,   7.7444, 800.0000, 785.5415],
        [  5.9412, 452.9097, 789.4225, 794.7924],
        [  0.0000,  11.9751, 604.9379, 519.3804],
        [ 11.3565, 426.6759, 798.9445, 793.5322],
        [450.7588,  15.4533, 800.0000, 671.4613],
        [  1.2946,   9.7367, 800.0000, 792.9683],
        [182.3338,  16.8376, 766.2789, 447.5916],
        [332.1723,  12.8783, 789.1204, 437.6362],
        [463.3968,  72.7026, 800.0000, 732.8840]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3612, 0.1713, 0.1517, 0.0738, 0.0729, 0.0697, 0.0645, 0.0626, 0.0612,
        0.0589, 0.0579, 0.0556, 0.0549, 0.0519, 0.0516], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 84, 44, 64,  3,  1,  1, 44, 78,  1, 82, 82],
       device='cuda:0')}, {'boxes': tensor([[  2.0651,   8.5510, 800.0000, 793.1689],
        [  0.0000,   3.3469, 798.6351, 797.8656],
        [  4.3730,   2.4946, 800.0000, 793.9565],
        [  3.6985,   3.9289, 797.0405, 793.0369],
        [  0.0000,  16.0620, 604.7466, 529.8729],
        [  1.6000,   7.6275, 800.0000, 785.7965],
        [  2.0651,   8.5510, 800.0000, 793.1689],
        [175.4532,   3.0894, 795.6978, 382.5604],
        [126.8517,   2.7075, 800.0000, 329.5028],
        [459.0437,  64.2087, 800.0000, 744.3422],
        [  2.0651,   8.5510, 800.0000, 793.1689],
        [443.9280,  11.3766, 800.0000, 687.6934],
        [  0.0000,  16.0620, 604.7466, 529.8729],
        [  6.0327,   5.6088, 797.6301, 792.6412],
        [ 40.5049,   7.6061, 574.3832, 270.5701],
        [255.1383, 332.9294, 786.0405, 792.6821]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3535, 0.1675, 0.1463, 0.0931, 0.0742, 0.0666, 0.0663, 0.0648, 0.0638,
        0.0606, 0.0575, 0.0561, 0.0553, 0.0513, 0.0511, 0.0507],
       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67,  1, 64, 84, 44,  1, 82, 78, 44, 44, 59,  1, 82],
       device='cuda:0')}, {'boxes': tensor([[3.0402e-01, 3.2779e-01, 8.0000e+02, 7.9509e+02],
        [0.0000e+00, 2.0946e+00, 8.0000e+02, 7.9721e+02],
        [4.8105e+00, 2.1093e+00, 8.0000e+02, 7.9281e+02],
        [3.0341e+00, 3.9850e+00, 7.9619e+02, 7.9571e+02],
        [1.2769e-01, 1.0083e+01, 8.0000e+02, 7.9266e+02],
        [1.3424e+02, 0.0000e+00, 7.8528e+02, 2.8494e+02],
        [1.7410e+02, 9.2330e+00, 7.9515e+02, 3.3261e+02],
        [1.7184e+00, 7.1994e+00, 8.0000e+02, 7.8489e+02],
        [2.1798e+01, 4.5208e+02, 7.8776e+02, 7.9575e+02],
        [1.2769e-01, 1.0083e+01, 8.0000e+02, 7.9266e+02],
        [1.9770e+01, 4.0739e+02, 7.9811e+02, 7.9091e+02],
        [1.7562e+02, 6.6992e+01, 7.8825e+02, 4.9480e+02]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3860, 0.1867, 0.1417, 0.0834, 0.0648, 0.0616, 0.0608, 0.0607, 0.0602,
        0.0556, 0.0547, 0.0508], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 84,  1, 44, 64,  3, 78,  1,  1], device='cuda:0')}, {'boxes': tensor([[  0.9483,   0.0000, 800.0000, 796.3425],
        [  1.9406,   2.9142, 800.0000, 800.0000],
        [  5.2716,   3.0496, 800.0000, 795.2717],
        [  3.1724,   4.4102, 795.2832, 794.3378],
        [164.5851,   4.6908, 799.6379, 354.3943],
        [  1.5052,   7.9246, 800.0000, 784.4395],
        [  1.4980,  17.0059, 587.0013, 519.8447],
        [  1.7692,  10.2494, 800.0000, 794.5635],
        [119.1624,   1.5427, 800.0000, 303.2852],
        [  8.2230, 397.5037, 787.0802, 772.3368],
        [195.5966, 355.1287, 782.3756, 778.3852],
        [164.9422,  60.6412, 792.8688, 497.8536],
        [451.1210,  99.8417, 800.0000, 758.7748],
        [302.4313, 307.1890, 791.5075, 781.4234],
        [451.1210,  99.8417, 800.0000, 758.7748]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3357, 0.1548, 0.1294, 0.0885, 0.0791, 0.0688, 0.0682, 0.0644, 0.0640,
        0.0577, 0.0544, 0.0541, 0.0530, 0.0527, 0.0513], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 44, 64,  1, 84,  1,  1, 44,  1, 82, 82, 44],
       device='cuda:0')}, {'boxes': tensor([[  1.0607,   0.0000, 800.0000, 796.8470],
        [  0.0000,   1.6440, 800.0000, 798.6417],
        [  4.4274,   1.8326, 800.0000, 793.6965],
        [  3.1740,   3.0138, 797.5769, 792.1426],
        [166.9481,   6.1631, 799.3591, 349.2205],
        [176.5330,  21.7904, 753.0228, 444.5823],
        [  1.1330,   9.6199, 800.0000, 793.2219],
        [  2.1938,   7.0636, 800.0000, 784.5066],
        [  7.9267, 455.6204, 758.6381, 796.6594],
        [ 18.6102, 436.3566, 792.3300, 791.9470],
        [  1.1330,   9.6199, 800.0000, 793.2219],
        [ 38.1966, 393.3464, 800.0000, 791.9370],
        [455.5015,  88.5413, 800.0000, 749.1158]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3981, 0.1679, 0.1377, 0.0753, 0.0740, 0.0612, 0.0610, 0.0596, 0.0573,
        0.0547, 0.0516, 0.0510, 0.0505], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 44,  1, 84, 64,  3,  1, 78, 82, 82], device='cuda:0')}, {'boxes': tensor([[1.9428e+00, 0.0000e+00, 7.9978e+02, 7.9581e+02],
        [0.0000e+00, 2.6874e+00, 8.0000e+02, 7.9859e+02],
        [3.4936e+00, 3.0883e+00, 8.0000e+02, 7.9314e+02],
        [2.6317e+00, 2.8509e+00, 7.9716e+02, 7.9299e+02],
        [1.1808e+02, 6.9183e+00, 8.0000e+02, 3.6130e+02],
        [5.9891e-01, 9.9946e+00, 8.0000e+02, 7.9327e+02],
        [1.2547e+00, 7.8709e+00, 7.9984e+02, 7.8715e+02],
        [0.0000e+00, 4.5763e+02, 7.8577e+02, 7.9445e+02],
        [7.6218e+00, 4.4783e+02, 7.9470e+02, 7.9229e+02],
        [1.3448e+02, 1.6350e+01, 7.9942e+02, 4.1578e+02],
        [0.0000e+00, 1.3437e+01, 6.1426e+02, 5.2649e+02],
        [5.9891e-01, 9.9946e+00, 8.0000e+02, 7.9327e+02],
        [4.7701e+00, 6.4241e+00, 7.9701e+02, 7.9315e+02]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.4092, 0.1787, 0.1674, 0.0882, 0.0693, 0.0672, 0.0672, 0.0666, 0.0633,
        0.0590, 0.0571, 0.0561, 0.0521], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 44, 84, 64,  3,  1,  1,  1, 78, 59], device='cuda:0')}, {'boxes': tensor([[2.1665e+00, 0.0000e+00, 8.0000e+02, 7.9561e+02],
        [1.6545e+00, 2.4877e+00, 8.0000e+02, 7.9648e+02],
        [4.6182e+00, 2.6391e+00, 8.0000e+02, 7.9315e+02],
        [3.4071e+00, 8.2956e-01, 7.9610e+02, 7.9175e+02],
        [1.6161e+02, 8.1858e+00, 7.9121e+02, 3.6664e+02],
        [3.4262e-01, 9.1057e+00, 8.0000e+02, 7.9370e+02],
        [2.0204e+00, 7.2895e+00, 7.9991e+02, 7.8730e+02],
        [2.2006e+00, 1.4008e+01, 6.1169e+02, 5.2596e+02],
        [1.3094e+02, 2.0757e+01, 7.9988e+02, 4.2189e+02],
        [3.4262e-01, 9.1057e+00, 8.0000e+02, 7.9370e+02],
        [2.5441e+01, 4.0439e+02, 8.0000e+02, 7.9307e+02],
        [1.5198e+02, 2.4777e+02, 7.6185e+02, 6.1664e+02],
        [0.0000e+00, 4.4708e+02, 7.7863e+02, 7.9289e+02],
        [2.2428e+02, 3.8078e+02, 7.9558e+02, 7.9476e+02]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3794, 0.1718, 0.1524, 0.0882, 0.0689, 0.0687, 0.0646, 0.0586, 0.0573,
        0.0564, 0.0559, 0.0519, 0.0511, 0.0506], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 44, 84, 64,  1,  1, 78,  1,  1,  3, 82],
       device='cuda:0')}, {'boxes': tensor([[1.8488e+00, 0.0000e+00, 8.0000e+02, 7.9595e+02],
        [2.8790e-01, 4.3322e+00, 8.0000e+02, 7.9797e+02],
        [2.3522e+00, 1.5138e+00, 8.0000e+02, 7.9369e+02],
        [3.5669e+00, 2.3935e+00, 7.9526e+02, 7.9286e+02],
        [2.3868e-01, 9.4084e+00, 8.0000e+02, 7.9334e+02],
        [1.3177e+00, 1.9850e+01, 5.8841e+02, 5.2301e+02],
        [1.4602e+01, 4.6461e+02, 7.9053e+02, 7.9536e+02],
        [1.5692e+00, 6.9691e+00, 8.0000e+02, 7.8677e+02],
        [1.2447e+02, 6.3527e+00, 7.9253e+02, 3.3806e+02],
        [1.0657e+02, 4.4470e+00, 8.0000e+02, 2.9355e+02],
        [2.3868e-01, 9.4084e+00, 8.0000e+02, 7.9334e+02],
        [6.2439e+01, 4.1415e+02, 8.0000e+02, 7.9297e+02],
        [4.5651e+02, 1.3480e+01, 8.0000e+02, 6.9254e+02]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3392, 0.1918, 0.1628, 0.0775, 0.0768, 0.0683, 0.0657, 0.0610, 0.0579,
        0.0570, 0.0554, 0.0526, 0.0520], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 84,  1,  3, 64, 44,  1, 78,  1, 44], device='cuda:0')}, {'boxes': tensor([[0.0000e+00, 0.0000e+00, 8.0000e+02, 7.9618e+02],
        [6.2042e-02, 0.0000e+00, 7.9952e+02, 7.9586e+02],
        [2.9083e+00, 2.1420e+00, 8.0000e+02, 7.9368e+02],
        [3.1266e+00, 4.7078e+00, 7.9732e+02, 7.9206e+02],
        [1.5378e+02, 8.4442e+00, 8.0000e+02, 3.3698e+02],
        [0.0000e+00, 8.2465e+00, 8.0000e+02, 7.9294e+02],
        [1.8715e+02, 6.6005e+01, 7.8618e+02, 4.9096e+02],
        [1.5899e+00, 5.5523e+00, 8.0000e+02, 7.8531e+02],
        [2.4247e+01, 4.4737e+02, 7.7735e+02, 7.9284e+02],
        [1.2291e+02, 1.8132e+00, 8.0000e+02, 2.9551e+02],
        [1.3850e+00, 4.1057e+02, 7.9213e+02, 7.7351e+02],
        [0.0000e+00, 8.2465e+00, 8.0000e+02, 7.9294e+02],
        [3.6992e+02, 4.3702e+01, 7.9640e+02, 5.1400e+02]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.4053, 0.1946, 0.1556, 0.0816, 0.0809, 0.0788, 0.0632, 0.0630, 0.0615,
        0.0560, 0.0553, 0.0537, 0.0503], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 44, 84,  1, 64,  3,  1,  1, 78, 44], device='cuda:0')}, {'boxes': tensor([[1.0437e+00, 0.0000e+00, 8.0000e+02, 7.9670e+02],
        [2.7069e+00, 3.8293e+00, 8.0000e+02, 7.9767e+02],
        [6.4110e+00, 1.7735e+00, 8.0000e+02, 7.9505e+02],
        [3.1786e+00, 4.7688e+00, 7.9546e+02, 7.9288e+02],
        [1.1168e+00, 8.9134e+00, 8.0000e+02, 7.9513e+02],
        [1.8089e+02, 9.0945e+00, 8.0000e+02, 3.7238e+02],
        [4.4278e-01, 8.7123e+00, 8.0000e+02, 7.8514e+02],
        [2.0483e+02, 4.6364e+01, 7.9150e+02, 4.9112e+02],
        [1.3360e+02, 2.2356e+00, 8.0000e+02, 2.8743e+02],
        [4.4343e+00, 5.3345e+00, 7.9735e+02, 7.9123e+02],
        [6.8369e+00, 4.4752e+02, 7.7570e+02, 7.9464e+02],
        [1.1168e+00, 8.9134e+00, 8.0000e+02, 7.9513e+02],
        [7.8459e+00, 4.0916e+02, 7.9455e+02, 7.7565e+02]], device='cuda:0',
       grad_fn=<StackBackward0>), 'scores': tensor([0.3416, 0.1830, 0.1564, 0.0826, 0.0710, 0.0625, 0.0613, 0.0575, 0.0541,
        0.0536, 0.0532, 0.0514, 0.0504], device='cuda:0',
       grad_fn=<IndexBackward0>), 'labels': tensor([82,  1, 44, 67, 84, 44, 64,  1,  1, 59,  3, 78,  1], device='cuda:0')}]
/workspace/ssd/model/retinanet.py:507: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  for img in images:
/workspace/ssd/model/transform.py:70: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  images = [img for img in images]
/workspace/ssd/model/transform.py:113: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  mean = torch.as_tensor(self.image_mean, dtype=dtype, device=device)
/workspace/ssd/model/transform.py:114: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  std = torch.as_tensor(self.image_std, dtype=dtype, device=device)
Traceback (most recent call last):
  File "convert.py", line 289, in <module>
    main(args)
  File "convert.py", line 244, in main
    'modelOutput' : {0 : 'batch_size'}}) 
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/__init__.py", line 320, in export
    custom_opsets, enable_onnx_checker, use_external_data_format)
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py", line 111, in export
    custom_opsets=custom_opsets, use_external_data_format=use_external_data_format)
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py", line 729, in _export
    dynamic_axes=dynamic_axes)
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py", line 493, in _model_to_graph
    graph, params, torch_out, module = _create_jit_graph(model, args)
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py", line 437, in _create_jit_graph
    graph, torch_out = _trace_and_get_graph_from_model(model, args)
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py", line 388, in _trace_and_get_graph_from_model
    torch.jit._get_trace_graph(model, args, strict=False, _force_outplace=False, _return_inputs_states=True)
  File "/opt/conda/lib/python3.7/site-packages/torch/jit/_trace.py", line 1166, in _get_trace_graph
    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/jit/_trace.py", line 132, in forward
    self._force_outplace,
  File "/opt/conda/lib/python3.7/site-packages/torch/jit/_trace.py", line 118, in wrapper
    outs.append(self.inner(*trace_inputs))
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/workspace/ssd/model/retinanet.py", line 533, in forward
    features = self.backbone(images.tensors)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/workspace/ssd/model/backbone_utils.py", line 45, in forward
    x = self.body(x)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/workspace/ssd/model/utils.py", line 66, in forward
    x = module(x)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
Traceback (most recent call last):
  File "convert.py", line 289, in <module>
    main(args)
  File "convert.py", line 244, in main
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    'modelOutput' : {0 : 'batch_size'}}) 
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/__init__.py", line 320, in export
    custom_opsets, enable_onnx_checker, use_external_data_format)
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py", line 111, in export
    custom_opsets=custom_opsets, use_external_data_format=use_external_data_format)
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py", line 729, in _export
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py", line 141, in forward
    dynamic_axes=dynamic_axes)
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py", line 493, in _model_to_graph
    input = module(input)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    graph, params, torch_out, module = _create_jit_graph(model, args)
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py", line 437, in _create_jit_graph
    graph, torch_out = _trace_and_get_graph_from_model(model, args)
  File "/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py", line 388, in _trace_and_get_graph_from_model
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    torch.jit._get_trace_graph(model, args, strict=False, _force_outplace=False, _return_inputs_states=True)
  File "/opt/conda/lib/python3.7/site-packages/torch/jit/_trace.py", line 1166, in _get_trace_graph
    result = self.forward(*input, **kwargs)
  File "/workspace/ssd/model/resnet.py", line 129, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/jit/_trace.py", line 132, in forward
    self._force_outplace,
  File "/opt/conda/lib/python3.7/site-packages/torch/jit/_trace.py", line 118, in wrapper
    outs.append(self.inner(*trace_inputs))
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torchvision/ops/misc.py", line 96, in forward
    return x * scale + bias
RuntimeError:     CUDA out of memory. Tried to allocate 626.00 MiB (GPU 1; 23.68 GiB total capacity; 19.80 GiB already allocated; 249.62 MiB free; 21.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONFreturn forward_call(*input, **kwargs)

  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/workspace/ssd/model/retinanet.py", line 533, in forward
    features = self.backbone(images.tensors)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/workspace/ssd/model/backbone_utils.py", line 45, in forward
    x = self.body(x)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/workspace/ssd/model/utils.py", line 66, in forward
    x = module(x)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/workspace/ssd/model/resnet.py", line 129, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1090, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torchvision/ops/misc.py", line 96, in forward
    return x * scale + bias
RuntimeError: CUDA out of memory. Tried to allocate 626.00 MiB (GPU 0; 23.69 GiB total capacity; 18.58 GiB already allocated; 467.56 MiB free; 20.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 878) of binary: /opt/conda/bin/python
Traceback (most recent call last):
  File "/opt/conda/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==1.10.0', 'console_scripts', 'torchrun')())
  File "/opt/conda/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/distributed/run.py", line 719, in main
    run(args)
  File "/opt/conda/lib/python3.7/site-packages/torch/distributed/run.py", line 713, in run
    )(*cmd_args)
  File "/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 261, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
convert.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2022-06-17_10:12:07
  host      : ff4d2b1d43c3
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 879)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2022-06-17_10:12:07
  host      : ff4d2b1d43c3
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 878)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
